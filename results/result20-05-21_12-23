nohup: les entrées sont ignorées
20_05_21_12-23
Starting script
Using backend: pytorch
##################################################
# Hidden node dimensions : [64, 32, 16, 8]
# Hidden edge dimensions : [32, 16, 16, 8]
# Hidden linear dimension : 32
# Dropout probability : 0.2
# Max epoch : 5000
# Initial learning rate : 1e-05
# Device : cuda
##################################################
Retrieving dataset ... Done !
Created GCN
48.82% of total null iterations
49.6% of null iterations in training set
Dataset size : 2552
Training set size : 1871

Starting training...

Epoch 0, loss 0.352518, accuracy 0.1179
Epoch 5, loss 0.350761, accuracy 0.1242
Epoch 10, loss 0.350079, accuracy 0.1238
Epoch 15, loss 0.348234, accuracy 0.1254
Epoch 20, loss 0.345286, accuracy 0.1242
Epoch 25, loss 0.342237, accuracy 0.1234
Epoch 30, loss 0.342273, accuracy 0.1238
Epoch 35, loss 0.340016, accuracy 0.1238
Epoch 40, loss 0.338675, accuracy 0.1250
Epoch 45, loss 0.336157, accuracy 0.1238
Epoch 50, loss 0.335508, accuracy 0.1242
Epoch 55, loss 0.334167, accuracy 0.1246
Epoch 60, loss 0.332372, accuracy 0.1246
Epoch 65, loss 0.329178, accuracy 0.1246
Epoch 70, loss 0.328558, accuracy 0.1246
Epoch 75, loss 0.327803, accuracy 0.1246
Epoch 80, loss 0.325245, accuracy 0.1246
Epoch 85, loss 0.323642, accuracy 0.1246
Epoch 90, loss 0.321867, accuracy 0.1246
Epoch 95, loss 0.321624, accuracy 0.1254
Epoch 100, loss 0.320490, accuracy 0.1242
Epoch 105, loss 0.313849, accuracy 0.1234
Epoch 110, loss 0.317241, accuracy 0.1242
Epoch 115, loss 0.314661, accuracy 0.1238
Epoch 120, loss 0.314054, accuracy 0.1238
Epoch 125, loss 0.311242, accuracy 0.1254
Epoch 130, loss 0.310729, accuracy 0.1238
Epoch 135, loss 0.309974, accuracy 0.1226
Epoch 140, loss 0.308688, accuracy 0.1234
Epoch 145, loss 0.306277, accuracy 0.1246
Epoch 150, loss 0.305670, accuracy 0.1246
Epoch 155, loss 0.303934, accuracy 0.1242
Epoch 160, loss 0.304293, accuracy 0.1246
Epoch 165, loss 0.304624, accuracy 0.1250
Epoch 170, loss 0.302243, accuracy 0.1246
Epoch 175, loss 0.302343, accuracy 0.1234
Epoch 180, loss 0.307346, accuracy 0.1238
Epoch 185, loss 0.300356, accuracy 0.1238
Epoch 190, loss 0.298613, accuracy 0.1246
Epoch 195, loss 0.298598, accuracy 0.1234
Epoch 200, loss 0.296980, accuracy 0.1242
Epoch 205, loss 0.296396, accuracy 0.1242
Epoch 210, loss 0.295256, accuracy 0.1246
Epoch 215, loss 0.294669, accuracy 0.1258
Epoch 220, loss 0.294146, accuracy 0.1242
Epoch 225, loss 0.293482, accuracy 0.1242
Epoch 230, loss 0.294403, accuracy 0.1234
Epoch 235, loss 0.293899, accuracy 0.1242
Epoch 240, loss 0.294439, accuracy 0.1242
Epoch 245, loss 0.293834, accuracy 0.1230
Epoch 250, loss 0.295707, accuracy 0.1242
Epoch 255, loss 0.291440, accuracy 0.1226
Epoch 260, loss 0.292602, accuracy 0.1254
Epoch 265, loss 0.291512, accuracy 0.1246
Epoch 270, loss 0.289152, accuracy 0.1242
Epoch 275, loss 0.290153, accuracy 0.1250
Epoch 280, loss 0.291038, accuracy 0.1258
Epoch 285, loss 0.292271, accuracy 0.1246
Epoch 290, loss 0.291495, accuracy 0.1254
Epoch 295, loss 0.289396, accuracy 0.1242
Epoch 300, loss 0.290975, accuracy 0.1246
Epoch 305, loss 0.292337, accuracy 0.1254
Epoch 310, loss 0.290828, accuracy 0.1246
Epoch 315, loss 0.290626, accuracy 0.1254
Epoch 320, loss 0.291233, accuracy 0.1250
Epoch 325, loss 0.291415, accuracy 0.1250
Epoch 330, loss 0.289711, accuracy 0.1234
Epoch 335, loss 0.289947, accuracy 0.1238
Epoch 340, loss 0.284747, accuracy 0.1246
Epoch 345, loss 0.290846, accuracy 0.1258
Epoch 350, loss 0.290642, accuracy 0.1234
Epoch 355, loss 0.288672, accuracy 0.1242
Epoch 360, loss 0.287962, accuracy 0.1266
Epoch 365, loss 0.287302, accuracy 0.1234
Epoch 370, loss 0.288295, accuracy 0.1238
Epoch 375, loss 0.290595, accuracy 0.1230
Epoch 380, loss 0.293202, accuracy 0.1226
Epoch 385, loss 0.288399, accuracy 0.1238
Epoch 390, loss 0.283412, accuracy 0.1254
Epoch 395, loss 0.287642, accuracy 0.1242
Epoch 400, loss 0.288281, accuracy 0.1223
